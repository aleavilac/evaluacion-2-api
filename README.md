# üöÄ Proyecto: API Serverless de Metadatos de Im√°genes

Este proyecto crea un sistema 100% serverless en AWS para registrar autom√°ticamente los metadatos de cualquier imagen subida a un bucket S3. Los metadatos se almacenan en DynamoDB y se exponen a trav√©s de una API HTTP para ser consultados o eliminados.

El despliegue del c√≥digo de las funciones Lambda est√° completamente automatizado con un pipeline de CI/CD usando GitHub Actions.

## üèõÔ∏è Arquitectura del Sistema

El flujo de datos es el siguiente:
1.  Un usuario sube un archivo (ej: `foto.jpg`) a un **Bucket S3**.
2.  S3 detecta el archivo y **dispara autom√°ticamente** la **Lambda 1 (`s3_file_event`)**.
3.  La Lambda 1 genera un ID √∫nico (`fileid`), extrae la metadata (nombre, tama√±o, etc.) y la **guarda en DynamoDB**.
4.  Un usuario (o una aplicaci√≥n) quiere ver los datos y llama a la **API Gateway**.
5.  La API Gateway **dispara la Lambda 2 (`get_image_metadata`)**.
6.  La Lambda 2 **lee o borra** datos de DynamoDB y devuelve la respuesta.

**Flujo Visual:**
`[üñºÔ∏è Archivo] ‚û°Ô∏è [AWS S3] ‚û°Ô∏è [Lambda 1] ‚û°Ô∏è [üóÇÔ∏è DynamoDB] ‚û°Ô∏è [üåê API Gateway] ‚û°Ô∏è [Lambda 2] ‚û°Ô∏è [üßë‚Äçüíª Usuario]`


### Diagrama de Arquitectura con Mermaid

```mermaid
flowchart TB
    %% --- Definici√≥n de Actores ---
    user[Usuario / Cliente API üßë‚Äçüíª]
    uploader[Usuario / Uploader üñºÔ∏è]

    %% --- Definici√≥n de Sub-gr√°ficos de Servicios ---
    subgraph "Almacenamiento (S3)"
        direction LR
        s3_bucket(Tu Bucket S3)
    end
    
    subgraph "API Gateway"
        apigw(ImageMetadataAPI)
    end

    subgraph "Funciones Lambda"
        direction TB
        s3_lambda(s3fileevent)
        api_lambda(getimagemetadata)
    end

    subgraph "Base de Datos (DynamoDB)"
        direction LR
        dynamo[(ImageMetadata)]
    end
    
    subgraph "Observabilidad (Monitoreo)"
        direction LR
        cwlogs(CloudWatch Logs)
    end

    %% --- Flujo 1: Carga de Archivo ---
    uploader -- Sube Archivo --> s3_bucket
    s3_bucket -- Evento ObjectCreated --> s3_lambda
    s3_lambda -- Escribe (put_item) --> dynamo
    
    %% --- Flujo 2: Consulta de API ---
    user -- HTTPS (GET / DELETE) --> apigw
    apigw -- Invoca --> api_lambda
    api_lambda -- Lee/Borra (get/delete_item) --> dynamo
    dynamo -- Devuelve Datos --> api_lambda
    api_lambda -- Respuesta JSON --> apigw
    apigw -- Respuesta JSON --> user

    %% --- Flujo 3: Logs de Monitoreo ---
    s3_lambda -- Escribe Logs --> cwlogs
    api_lambda -- Escribe Logs --> cwlogs
    apigw -- Escribe Logs --> cwlogs

    %% --- Definici√≥n de Estilos ---
    style user fill:#e0f2f7,stroke:#3498db,stroke-width:2px,color:#2c3e50
    style uploader fill:#e0f2f7,stroke:#3498db,stroke-width:2px,color:#2c3e50
    style s3_bucket fill:#fcf2da,stroke:#f1c40f,stroke-width:2px,color:#2c3e50
    style s3_lambda fill:#d5f5e3,stroke:#2ecc71,stroke-width:2px,color:#2c3e50
    style api_lambda fill:#d5f5e3,stroke:#2ecc71,stroke-width:2px,color:#2c3e50
    style dynamo fill:#ebf5fb,stroke:#2e86c1,stroke-width:2px,color:#2c3e50
    style apigw fill:#f6e4f8,stroke:#9b59b6,stroke-width:2px,color:#2c3e50
    style cwlogs fill:#fdebd0,stroke:#e67e22,stroke-width:2px,color:#2c3e50

```

## ‚ú® Caracter√≠sticas

* **Ingesta Autom√°tica:** No hay que ejecutar ning√∫n script manual. Solo sube un archivo y la metadata se guarda.
* **Pipeline CI/CD:** El c√≥digo de las Lambdas se actualiza autom√°ticamente en AWS cada vez que haces `git push` a este repositorio.
* **API HTTP:** Una API simple para `GET` (listar todo), `GET /id` (ver uno) y `DELETE /id` (borrar uno).
* **100% Serverless:** Cero servidores que administrar. Paga solo por lo que usas.

---

## üìã Requisitos Previos

Antes de empezar, necesitar√°s:
* **Acceso a una Cuenta de AWS:** Este proyecto est√° pensado para un entorno de laboratorio (como AWS Academy) donde se proveen credenciales de sesi√≥n.
* **Credenciales de Laboratorio:** Necesitar√°s tus `aws_access_key_id`, `aws_secret_access_key` y `aws_session_token`.
* **Cuenta de GitHub:** Para clonar el repositorio y configurar el pipeline.

---

## üõ†Ô∏è Fase 1: Configuraci√≥n Manual en AWS

El pipeline de GitHub *solo* despliega el c√≥digo. La infraestructura (base de datos, roles, API) debe crearse manualmente la primera vez.

### 1. Crear Base de Datos (DynamoDB)

1.  Ve al servicio **DynamoDB**.
2.  Haz clic en **"Crear tabla"**.
3.  **Nombre de la tabla:** `ImageMetadata`
4.  **Clave de partici√≥n:** `image_id` (deja el tipo como `String`).
5.  Deja el resto por defecto y haz clic en **"Crear tabla"**.

### 2. Crear Almacenamiento (S3)

1.  Ve al servicio **S3**.
2.  Haz clic en **"Crear bucket"**.
3.  **Nombre del bucket:** Elige un nombre √∫nico global (ej: `mi-proyecto-lambda-12345`).
4.  **Regi√≥n:** Aseg√∫rate de que est√© en la misma regi√≥n que tu laboratorio (ej: `us-east-1`).
5.  Deja el resto por defecto y haz clic en **"Crear bucket"**.

### 3. Crear Funciones (Lambda)

Crearemos dos funciones vac√≠as que nuestro pipeline llenar√° con c√≥digo.

**Funci√≥n 1: `s3_file_event` (La que escribe en la BD)**
1.  Ve al servicio **Lambda** -> **"Crear funci√≥n"**.
2.  Selecciona **"Crear desde cero"**.
3.  **Nombre de la funci√≥n:** `s3_file_event`
4.  **Runtime:** `Python 3.12` (o el que te provea el laboratorio).
5.  **Rol de ejecuci√≥n:** Elige "Usar un rol existente" y selecciona el `labrole` que creaste.
6.  Haz clic en "Crear funci√≥n".

**Funci√≥n 2: `get_image_metadata` (La que lee desde la API)**
1.  Vuelve a **Lambda** -> **"Crear funci√≥n"**.
2.  **Nombre de la funci√≥n:** `get_image_metadata`
3.  **Runtime:** `Python 3.12`.
4.  **Rol de ejecuci√≥n:** "Usar un rol existente" y selecciona el mismo `labrole`.
5.  Haz clic en "Crear funci√≥n".

### 5. Configurar Ambas Lambdas

Debes hacer esto para **AMBAS** funciones (`s3_file_event` y `get_image_metadata`).

1.  **A√±adir Variable de Entorno:**
    * Ve a la pesta√±a **"Configuraci√≥n"**.
    * Clic en **"Variables de entorno"** -> "Editar".
    * Haz clic en **"A√±adir variable de entorno"**.
    * **Clave:** `TABLE_NAME`
    * **Valor:** `ImageMetadata` (el nombre de tu tabla).
    * Haz clic en **"Guardar"**.

### 6. Conectar S3 con Lambda 1

1.  Ve a tu **Bucket S3** (el que creaste en el paso 2).
2.  Haz clic en la pesta√±a **"Propiedades"**.
3.  Baja hasta **"Notificaciones de eventos"** y haz clic en "Crear notificaci√≥n de eventos".
4.  **Nombre:** `trigger-lambda-s3`
5.  **Tipos de eventos:** Marca la casilla `s3:ObjectCreated:*`.
6.  **Destino:** Elige "Funci√≥n de Lambda".
7.  **Lambda:** Elige `s3_file_event`.
8.  Haz clic en "Guardar cambios".

### 7. Crear la API (API Gateway)

1.  Ve al servicio **API Gateway**.
2.  Busca el cuadro de **HTTP API** (la azul/verde) y haz clic en **"Crear" (Build)**.
3.  **Integraciones:** Haz clic en "A√±adir integraci√≥n".
    * Elige `Lambda`.
    * Regi√≥n: `us-east-1` (o tu regi√≥n).
    * Funci√≥n de Lambda: `get_image_metadata`
4.  **Nombre de la API:** `ImageMetadataAPI` y haz clic en "Siguiente".
5.  **Configurar Rutas:** Aqu√≠ creamos los 3 endpoints.
    * **Ruta 1 (Crear):**
        * M√©todo: `GET`
        * Ruta: `/metadata`
        * Integraci√≥n: `get_image_metadata`.
    * **Ruta 2 (Crear):**
        * M√©todo: `GET`
        * Ruta: `/metadata/{image_id}` (¬°importante usar las llaves!)
        * Integraci√≥n: `get_image_metadata`.
    * **Ruta 3 (Crear):**
        * M√©todo: `DELETE`
        * Ruta: `/metadata/{image_id}`
        * Integraci√≥n: `get_image_metadata`.
6.  Haz clic en "Siguiente".
7.  **Etapas:** Deja el `$default` y haz clic en "Siguiente".
8.  Haz clic en **"Crear"**.
9.  Copia la **"URL de invocaci√≥n"**. ¬°La necesitar√°s para probar!

---

## üöÄ Fase 2: Configuraci√≥n y Despliegue del C√≥digo

Ahora que la infraestructura est√° lista, conectamos este repositorio.

### 1. Clonar el Repositorio

```bash
git clone [https://github.com/tu-usuario/tu-repositorio.git](https://github.com/tu-usuario/tu-repositorio.git)
cd tu-repositorio

```
2. Configurar los Secretos del Pipeline
El pipeline necesita las credenciales de tu laboratorio para conectarse a AWS.

Ve a tu repositorio en GitHub.

Ve a Settings -> Secrets and variables -> Actions.

Haz clic en "New repository secret" y crea los siguientes tres secretos:

LAB_AWS_ACCESS_KEY_ID (Pega la clave de acceso de tu laboratorio)

LAB_AWS_SECRET_ACCESS_KEY (Pega la clave secreta de tu laboratorio)

LAB_AWS_SESSION_TOKEN (Pega el token de sesi√≥n de tu laboratorio)

‚ö†Ô∏è ¬°IMPORTANTE! Estas credenciales de laboratorio expiran. Si el pipeline falla con un error Invalid security token, debes volver aqu√≠ y pegar las nuevas credenciales de tu sesi√≥n de laboratorio.

3. Desplegar
¬°Esta es la parte f√°cil! El archivo .github/workflows/deploy.yml est√° listo. Simplemente haz un push (o un commit si ya clonaste) a tu rama main o master.


# Haz un peque√±o cambio (a√±ade un espacio en este README)
git add .
git commit -m "Despliegue inicial de c√≥digo Lambda"
git push
Ve a la pesta√±a "Actions" en GitHub. Ver√°s tu pipeline ejecutarse y ponerse en verde ‚úÖ. ¬°Tu c√≥digo ya est√° en AWS!

üß™ Fase 3: Pruebas del Sistema Completo
Prueba de Escritura (S3 -> Lambda 1 -> DB):

Ve a tu Bucket S3.

Sube un archivo, ej: kuromi.jpg.

Ve a DynamoDB -> ImageMetadata -> Explorar elementos.

Resultado: Deber√≠as ver un nuevo √≠tem con image_id: "kuromi.jpg" y todos sus metadatos (incluyendo el fileid √∫nico).

Prueba de Lectura (API -> Lambda 2 -> DB):

Toma tu URL de invocaci√≥n de la API.

Listar Todo: Pega esto en tu navegador: {tu-url}/metadata

Obtener Uno: Pega esto en tu navegador: {tu-url}/metadata/kuromi.jpg

Prueba de Borrado (API -> Lambda 2 -> DB):

Abre una terminal.

Ejecuta curl:

Bash

curl -X DELETE "{tu-url}/metadata/kuromi.jpg"
Resultado: Deber√≠as ver el mensaje "Item eliminado".

## C√≥mo Probar DELETE con Postman
Sigue estos pasos:

Abre Postman.

Elige el m√©todo: Al lado de la barra de URL, haz clic en el men√∫ desplegable (que usualmente dice GET) y c√°mbialo a DELETE.

Pega tu URL: En la barra de URL, pega la direcci√≥n completa de tu API, incluyendo el image_id del archivo que quieres borrar.

Ejemplo: https://9gvcgntbvi.execute-api.us-east-1.amazonaws.com/metadata/kuromi.jpg

Env√≠a la solicitud: No necesitas configurar nada m√°s (ni Headers ni Body). Simplemente haz clic en el bot√≥n azul "Send".

## Resultados Esperados
1. Respuesta Exitosa
Si funciona, ver√°s la respuesta de tu Lambda en la parte inferior de la pantalla, con un "Status: 200 OK":

JSON
"Item eliminado"

2. Verificaci√≥n Final
Para confirmar al 100% que se borr√≥:

Vuelve a tu navegador (o a una nueva pesta√±a en Postman).

Haz un GET a la ruta /metadata (la que lista todo).

Resultado: La lista JSON ahora deber√≠a estar vac√≠a [] (o ya no deber√≠a incluir el √≠tem que borraste).

## üêû Troubleshooting (Soluci√≥n de Problemas)
Error: Invalid security token en "Actions"

Causa: Tus credenciales de laboratorio en los Secretos de GitHub expiraron.

Soluci√≥n: Obt√©n nuevas credenciales de tu laboratorio y actualiza los 3 secretos LAB_... en GitHub.

Error: KeyError: 'TABLE_NAME' en CloudWatch

Causa: Olvidaste a√±adir la Variable de Entorno TABLE_NAME a una de tus Lambdas (o no la guardaste).

Soluci√≥n: Ve a la Configuraci√≥n de ambas Lambdas y aseg√∫rate de que la variable exista y est√© guardada.

Error: ImportModuleError en CloudWatch

Causa: El "Manejador" (Handler) en la Configuraci√≥n de Runtime de la Lambda est√° mal.

Soluci√≥n: Aseg√∫rate de que el Manejador est√© configurado como lambda_function.lambda_handler.

Error: {"message": "Not Found"} al usar la API

Causa: Est√°s llamando a una ruta (ej: /metadata/test.jpg) que no creaste en API Gateway.

Soluci√≥n: Vuelve al Paso 7 y aseg√∫rate de haber creado las rutas GET /metadata/{image_id} y DELETE /metadata/{image_id}.

